# Evaluation of Homomorphic Encryption to Enhance the Privacy of AI-Enabled Insider Risk Analysis
## Marco Paes, Purdue University

### Abstract
The increasing use of artificial intelligence (AI) in insider threat detection has enhanced organizationsâ€™ ability to identify malicious or negligent employee behaviors. How-ever, the same systems that monitor user activity at scale also pose serious privacy challenges, as they often require direct access to sensitive behavioral data. This project ex-plores the use of homomorphic encryption (HE) to enable privacy-preserving machine learning for insider risk analy-sis, allowing computation on encrypted behavioral data without decryption. Using the Carnegie Mellon CERT In-sider Threat Dataset, this work aims to implement a proof-of-concept model that integrates HE into the inference stage of user behavior analytics (UEBA). The focus is to evaluate the tradeoffs between analytic performance, computational efficiency, and privacy preservation, and to determine whether HE can be adapted to insider risk pipe-lines more effectively than hybrid approaches such as HE combined with multi-party computation (MPC).


https://github.com/user-attachments/assets/74cae03f-03a3-4e1a-adc6-0c7f893fd9ec

